{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "semantic denoised hashing , which uses basic semantic hashing but denoises the input first then hashes for more robust prediction , model learns the important features more"
      ],
      "metadata": {
        "id": "92iVnDoAWI06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports and mnist dataset"
      ],
      "metadata": {
        "id": "moL62mwJTMI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Dense,Flatten,Reshape,BatchNormalization,GaussianNoise\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()\n",
        "x_train=x_train.astype('float32')/255.0\n",
        "x_test=x_test.astype('float32')/255.0\n",
        "x_train=x_train.reshape(-1,28*28)\n",
        "x_test=x_test.reshape(-1,28*28)"
      ],
      "metadata": {
        "id": "-lP4R3aIWIV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use kl divergence loss for sparse autoencoder so important features are learned and used. All training data is converted to its denoised form using this autoencoder."
      ],
      "metadata": {
        "id": "Jj48L37STZlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "def kl_divergence(p,q):\n",
        "  return p*tf.math.log(p/q)+(1-p)*tf.math.log((1-p)/(1-q))\n",
        "\n",
        "class SparseAutoencoder(Model):\n",
        "  def __init__(self,sparsity_target=0.1,sparsity_weight=0.2):\n",
        "    super(SparseAutoencoder,self).__init__()\n",
        "    self.sparsity_target=sparsity_target\n",
        "    self.sparsity_weight=sparsity_weight\n",
        "    self.hidden_layer=Dense(128,activation=\"sigmoid\",name=\"hidden1\")\n",
        "    self.output_layer=Dense(28*28,activation=\"sigmoid\",name=\"output\")\n",
        "  def call(self,inputs,training=False):\n",
        "    hidden=self.hidden_layer(inputs)\n",
        "    outputs=self.output_layer(hidden)\n",
        "    return hidden,outputs\n",
        "  def compute_losses(self,x):\n",
        "    hidden,outputs=self(x)\n",
        "    reconstruction_loss=tf.reduce_mean(tf.square(x-outputs))\n",
        "    hidden_mean=tf.reduce_mean(hidden,axis=0)\n",
        "    sparsity_loss=tf.reduce_sum(kl_divergence(self.sparsity_target,hidden_mean))\n",
        "    total_loss=reconstruction_loss+self.sparsity_weight*sparsity_loss\n",
        "    return total_loss\n",
        "\n",
        "sparsity_target=0.1\n",
        "sparsity_weight=0.2\n",
        "autoencoder=SparseAutoencoder(sparsity_target,sparsity_weight)\n",
        "optimizer=Adam(0.01)\n",
        "epochs=10\n",
        "batch_size=256\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i in range(0,len(x_train),batch_size):\n",
        "    x_batch=x_train[i:i+batch_size]\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss=autoencoder.compute_losses(x_batch)\n",
        "      grads=tape.gradient(loss,autoencoder.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads,autoencoder.trainable_variables))\n",
        "  print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.numpy():.4f}\")\n",
        "\n",
        "hidden,x_train=autoencoder(x_train)\n",
        "x_train=x_train.numpy()\n",
        "\"\"\"def plot_images(original,reconstructed,n_images=5):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    for i in range(n_images):\n",
        "      plt.subplot(2,n_images,i+1)\n",
        "      plt.imshow(original[i].reshape(28,28),cmap='gray')\n",
        "      plt.title(\"original\")\n",
        "      plt.axis(\"off\")\n",
        "      plt.subplot(2,n_images,n_images+i+1)\n",
        "      plt.imshow(reconstructed[i].reshape(28,28),cmap='gray')\n",
        "      plt.title(\"denoised\")\n",
        "      plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_images(x_test,reconstructed)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bZe_8JcHh5Wh",
        "outputId": "7b59e118-cf3e-48ff-ef98-91eae674df68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0687\n",
            "Epoch 2/10, Loss: 0.0527\n",
            "Epoch 3/10, Loss: 0.0417\n",
            "Epoch 4/10, Loss: 0.0379\n",
            "Epoch 5/10, Loss: 0.0534\n",
            "Epoch 6/10, Loss: 0.0711\n",
            "Epoch 7/10, Loss: 0.0781\n",
            "Epoch 8/10, Loss: 0.0771\n",
            "Epoch 9/10, Loss: 0.0751\n",
            "Epoch 10/10, Loss: 0.0742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def plot_images(original,reconstructed,n_images=5):\\n    plt.figure(figsize=(10,4))\\n    for i in range(n_images):\\n      plt.subplot(2,n_images,i+1)\\n      plt.imshow(original[i].reshape(28,28),cmap=\\'gray\\')\\n      plt.title(\"original\")\\n      plt.axis(\"off\")\\n      plt.subplot(2,n_images,n_images+i+1)\\n      plt.imshow(reconstructed[i].reshape(28,28),cmap=\\'gray\\')\\n      plt.title(\"denoised\")\\n      plt.axis(\"off\")\\n    plt.tight_layout()\\n    plt.show()\\n\\nplot_images(x_test,reconstructed)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def add_noise(images,noise_factor=0.2):\n",
        "  noise=np.random.normal(loc=0.0,scale=noise_factor,size=images.shape)\n",
        "  noisy_images=images+noise\n",
        "  noisy_images=np.clip(noisy_images,0.0,1.0)\n",
        "  return noisy_images\n",
        "\n",
        "x_train=add_noise(x_train)\n",
        "x_test=add_noise(x_test)\"\"\""
      ],
      "metadata": {
        "id": "6IUrrs8mYiRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "making another layered network that will later be used for semantic hashing. Gaussian noise to the internal layer may help."
      ],
      "metadata": {
        "id": "Ov4iAX6GTxND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "yXY3mQ5SV8ni",
        "outputId": "1e37165a-94c2-417b-b362-33fce06d91ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m200,960\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_20               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_21               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ coding (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m3,870\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m3,968\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_23               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │         \u001b[38;5;34m201,488\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_20               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_21               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ coding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_23               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">201,488</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m479,278\u001b[0m (1.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">479,278</span> (1.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m477,742\u001b[0m (1.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">477,742</span> (1.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "input_img=Input(shape=(28*28,))\n",
        "x=Dense(256,activation='relu')(input_img)\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "x=BatchNormalization()(x)\n",
        "\n",
        "#x=GaussianNoise(0.05)(x)\n",
        "coding=Dense(30,activation='sigmoid',name='coding')(x)\n",
        "\n",
        "x=Dense(128,activation='relu')(coding)\n",
        "x=BatchNormalization()(x)\n",
        "x=Dense(256,activation='relu')(x)\n",
        "x=BatchNormalization()(x)\n",
        "output_img=Dense(28*28,activation='sigmoid')(x)\n",
        "\n",
        "autoencoder=Model(input_img,output_img)\n",
        "autoencoder.compile(optimizer='adam',loss='mse')\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using the sparse autoencoder output as input"
      ],
      "metadata": {
        "id": "ekbSn4pMUBoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x_train,x_train,epochs=20,batch_size=256,validation_data=(x_test,x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zci4gBtVXCyk",
        "outputId": "f697f266-ff2c-4612-a610-9d70dfa52479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - loss: 0.1099 - val_loss: 0.0454\n",
            "Epoch 2/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0273\n",
            "Epoch 3/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0241\n",
            "Epoch 4/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 0.0235\n",
            "Epoch 5/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 9.7374e-04 - val_loss: 0.0229\n",
            "Epoch 6/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 8.5025e-04 - val_loss: 0.0227\n",
            "Epoch 7/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 7.7278e-04 - val_loss: 0.0223\n",
            "Epoch 8/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.2089e-04 - val_loss: 0.0219\n",
            "Epoch 9/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.1561e-04 - val_loss: 0.0217\n",
            "Epoch 10/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.5645e-04 - val_loss: 0.0216\n",
            "Epoch 11/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.3640e-04 - val_loss: 0.0214\n",
            "Epoch 12/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.1852e-04 - val_loss: 0.0211\n",
            "Epoch 13/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 6.0525e-04 - val_loss: 0.0211\n",
            "Epoch 14/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.7483e-04 - val_loss: 0.0209\n",
            "Epoch 15/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.4010e-04 - val_loss: 0.0209\n",
            "Epoch 16/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 5.5155e-04 - val_loss: 0.0207\n",
            "Epoch 17/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5.2142e-04 - val_loss: 0.0207\n",
            "Epoch 18/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.2835e-04 - val_loss: 0.0206\n",
            "Epoch 19/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.1693e-04 - val_loss: 0.0207\n",
            "Epoch 20/20\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.0678e-04 - val_loss: 0.0203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9fd506a490>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating simple binary hashes"
      ],
      "metadata": {
        "id": "C8XiPOkPUHe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder=Model(input_img,coding)\n",
        "hashes=encoder.predict(x_test)\n",
        "binary_hashes=(hashes>0.5).astype(int)\n",
        "print(\"Sample Hashes:\")\n",
        "for i in range(5):\n",
        "  print(binary_hashes[i])\n",
        "print(len(binary_hashes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL8E5XZnXIEC",
        "outputId": "9508c0a4-e88f-4d42-cb04-daff7d9a9323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Sample Hashes:\n",
            "[0 0 1 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1]\n",
            "[1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1]\n",
            "[0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0]\n",
            "[1 1 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0]\n",
            "[1 1 1 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 1]\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "putting them and dictionary form, and visualising similar images based on how they were hashed"
      ],
      "metadata": {
        "id": "tgXTiuyOUhha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "hash_dict=defaultdict(list)\n",
        "for i,h in enumerate(binary_hashes):\n",
        "  hash_key=tuple(h)\n",
        "  hash_dict[hash_key].append(i)\n",
        "\n",
        "def plot_similar_images(indices,num_images=5):\n",
        "  plt.figure(figsize=(15,5))\n",
        "  for i,idx in enumerate(indices[:num_images]):\n",
        "    plt.subplot(1,num_images,i+1)\n",
        "    plt.imshow(x_test[idx].reshape(28,28),cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "random_hash=next(iter(hash_dict))\n",
        "print(f\"Hash: {random_hash}\")\n",
        "plot_similar_images(hash_dict[random_hash])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "wIbFCnzKXW1q",
        "outputId": "96deb664-6735-4b95-9a5b-8316e57c0cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hash: (0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAADcCAYAAAD9epGpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAACTJJREFUeJzt3U2I1WUbBnBnsoUVREUfJn1QYISSfSAFFhWSSC0KskVF7ixwiFokWRGVmySioIVBQqvaCLXIEIlaCNEHTEQwlUrToo8hsaaoCPug0+bd9PLez1zv3zkz58z8fttrzn0ex/Pn8lncnpFer9dbAgA0jc73AQBgGChMAAgoTAAIKEwACChMAAgoTAAIKEwACChMAAgoTAAILE1/cGRkpJ/ngKE36P9plmcY2mZ6ht0wASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASCgMAEgsHS+DwAMt0ceeaTT6yYmJsps7969XY8DfeOGCQABhQkAAYUJAAGFCQABhQkAAYUJAIGRXq/Xi35wZKTfZ5k1mzZtKrMtW7aU2dTUVHPusWPHyuzVV18ts++++67Mvvjii+Z7MjzCR2ne9OsZbv25//777zL766+/yqz1rO3atavMvv322zKbydtvv11mBw8e7DyX4THTM+yGCQABhQkAAYUJAAGFCQABhQkAAYUJAIEFuVby5ZdfltmFF144dwf5j19++aXMPv300zk8yfz55ptvyuyZZ54ps/Hx8X4cpy8W61rJnXfeWWYbNmwos9b610knnXRcZ+rip59+KrPffvut08zR0fpO0lq5WbJkyZKPP/64zD777LMyu/vuu2c+2P/wyiuvNPPVq1eX2ddff11mrTWg1jfWzAdrJQAwCxQmAAQUJgAEFCYABBQmAAQUJgAEFCYABBbkHub69evL7LLLLiuzzz//vDn30ksvLbMrr7yyzG644YYyW7FiRZm1dpvOO++8Mjsera9cOnr0aJktX76883s+99xzZfbQQw91njvXFuseZle7d+8us1WrVpXZ1Vdf3Y/j9EXrdz7on5fZ8v3335fZ2WefPYcnmZk9TACYBQoTAAIKEwACChMAAgoTAAIKEwACC3KtZNCcdtppZXb55ZeX2UcffVRma9euPZ4jlY4dO1Zmhw8fLrOZVnJOP/30MhsbGyuzF198sTl3kAz6msAwPcOtZ+biiy/uy3ueeuqpZfbggw+W2VNPPVVmTz/9dJkN2ufl5JNPbubXXHNNp7mTk5NltnLlyk4z+8VaCQDMAoUJAAGFCQABhQkAAYUJAAGFCQABayXEbr/99jLbs2dP87UTExNlduONN5bZ9PT0zAcbEIO2JvDfPMO03HTTTc18//79neY+9thjZbZz585OM/vFWgkAzAKFCQABhQkAAYUJAAGFCQABhQkAgaXzfQAGy1lnnVVmu3btKrPR0fa/vXbs2FFmw7Q6AsNs3bp1Zfbyyy93nvvVV1+V2euvv9557qBxwwSAgMIEgIDCBICAwgSAgMIEgIDCBICAtRL+ZWxsrMzOPPPMMvvxxx+bcw8dOtT5TMDsePLJJ8vs3HPP7Tz32WefLbPDhw93njto3DABIKAwASCgMAEgoDABIKAwASCgMAEgYK1kEWp9Y8H27ds7zbztttua+cTERKe5wP9nzZo1ZXbJJZd0nnvkyJEyO3DgQOe5w8QNEwACChMAAgoTAAIKEwACChMAAgoTAAIKEwAC9jAXoZtvvrnMTjzxxDJ75513yuz9998/rjMBuVWrVpXZvn37yuycc84ps6NHjzbfc8OGDWW2WPas3TABIKAwASCgMAEgoDABIKAwASCgMAEgYK1kgVq2bFmZbdy4scz++OOPMnviiSfK7M8//8wOBhy3LVu2lNny5cs7zZyenm7mi2V1pMUNEwACChMAAgoTAAIKEwACChMAAgoTAALWShaobdu2ldkVV1xRZvv37y+z995777jOBOQOHTpUZhdddFGZ9Xq9Mjty5EiZbd68OTvYIuaGCQABhQkAAYUJAAGFCQABhQkAAYUJAAFrJUPqlltuaeaPP/54mf38889ltmPHjs5nAv5t9erVZbZ169bma1urI6Oj9V1namqqzDZt2lRm4+PjzfPghgkAEYUJAAGFCQABhQkAAYUJAAGFCQABayUD7IwzziizF154ofnaE044ocz27dtXZh988MHMBwMiDz/8cJndddddnee2VkfuuOOOMvvwww87vydumAAQUZgAEFCYABBQmAAQUJgAEFCYABBQmAAQGOn1er3oB0dG+n2WRam1L9naibzqqquacycnJ8ts48aNnV5HW/gozRvPcHdr1qwps5deeqnM1q5dW2YzfV667lrape5upr8TN0wACChMAAgoTAAIKEwACChMAAgoTAAIWCuZZytXriyzgwcPdp576623ltnevXs7z6VmrWS4bd++vcy2bt1aZitWrCiz1u98ps/L9ddfX2bvvvtu87V0Y60EAGaBwgSAgMIEgIDCBICAwgSAgMIEgMDS+T7AYnDBBReU2VtvvdVp5rZt25r5m2++2WkuDLNly5Y180cffbTM7rnnnjJrrY60/PDDD2U2NjbWfO34+Hin96R/3DABIKAwASCgMAEgoDABIKAwASCgMAEgYK1kDtx7771ldv7553eaeeDAgWY+6N+cAf2wbt26Zt5aK+mH3bt3l9mePXvm8CTMBjdMAAgoTAAIKEwACChMAAgoTAAIKEwACFgrmSXXXnttmd1///1zeBJYvB544IG+zG2tab322mtl9sYbb/TjOMwTN0wACChMAAgoTAAIKEwACChMAAgoTAAIWCuZJdddd12ZnXLKKZ1mTk5Oltmvv/7aaSYsZPfdd18z37x5c6e5v//+e5k9//zznWYyfNwwASCgMAEgoDABIKAwASCgMAEgoDABIKAwASBgD3OeffLJJ2W2fv36Mpuenu7HcWCoTU1NNfOdO3fO0UlYiNwwASCgMAEgoDABIKAwASCgMAEgoDABIDDS6/V60Q+OjPT7LDDUwkdp3niGoW2mZ9gNEwACChMAAgoTAAIKEwACChMAAgoTAALxWgkALGZumAAQUJgAEFCYABBQmAAQUJgAEFCYABBQmAAQUJgAEFCYABD4B80rzEBKiwCMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gini score to see the model performance"
      ],
      "metadata": {
        "id": "Izc48DxJUsF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gini_purity(groups,labels):\n",
        "  total_purity=0\n",
        "  for indices in groups.values():\n",
        "    if len(indices)>1:\n",
        "      label_counts=np.bincount(labels[indices])\n",
        "      probabilities=label_counts/np.sum(label_counts)\n",
        "      gini=1-np.sum(probabilities**2)\n",
        "      total_purity+=gini*len(indices)\n",
        "  return total_purity/len(labels)\n",
        "\n",
        "gini_score=gini_purity(hash_dict,y_test)\n",
        "print(f\"Gini Purity: {gini_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oakAVCZ5YIq2",
        "outputId": "96061604-6bca-4984-a309-22b4a9bab492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Purity: 0.0322\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKAu9l8zbFOg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}